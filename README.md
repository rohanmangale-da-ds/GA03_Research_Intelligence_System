
ğŸ“© Gmail - rohanmangale4001@gmail.com

--------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------
## ğŸ¤– Research Intelligence RAG Chatbot

An AI-powered Research Assistant that allows users to upload documents and interact with them using Retrieval-Augmented Generation (RAG).

This system enables intelligent document understanding by combining semantic search, vector embeddings, and LLM-based reasoning â€” all inside a clean and interactive Streamlit interface.

## ğŸ“¸ Screenshots
1. User Interface (UI)
<img width="1910" height="962" alt="image" src="https://github.com/user-attachments/assets/5b20fba0-fd19-413b-bb68-a1d3529061ca" />

2. Extracting Information from Documents
<img width="1912" height="959" alt="image" src="https://github.com/user-attachments/assets/89003453-f533-4de2-ac1c-e50c201685d3" />

3. AI-Powered Question Answering from Documents
<img width="1914" height="959" alt="image" src="https://github.com/user-attachments/assets/b64a1cc9-450e-46b9-9c98-0cded798c852" />


### âœ¨ Key Features

âœ” Upload and analyze multiple documents (PDF / TXT)
âœ” Ask natural language questions about uploaded documents
âœ” Uses Retrieval-Augmented Generation (RAG)
âœ” Fast semantic search using FAISS
âœ” Clean and modern Streamlit UI
âœ” Modular, scalable, and production-ready architecture
âœ” Designed for research, legal, academic, and enterprise use cases


### ğŸ’¡ Tech Stack

1. UI	-> Streamlit
2. LLM	-> Groq (LLaMA 3.x series)
3. Embeddings -> 	HuggingFace (Sentence Transformers)
4. Vector Database ->	FAISS
5. Backend ->	Python
6. Configuration ->	.env, settings.py
7. Architecture ->	Modular & Scalable

### ğŸ“ Project Structure

```
GA03_Research_Intelligence_System/
â”‚
â”œâ”€â”€ .streamlit/
â”‚   â””â”€â”€ config.toml              # UI theme configuration
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ __init__.py
â”‚   â””â”€â”€ settings.py              # Centralized configuration
â”‚
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ chain.py                 # RAG pipeline logic
â”‚   â”œâ”€â”€ document_processor.py    # Document parsing & chunking
â”‚   â”œâ”€â”€ embeddings.py            # Embedding generation
â”‚   â””â”€â”€ vector_store.py          # FAISS vector store
â”‚
â”œâ”€â”€ ui/
â”‚   â”œâ”€â”€ chat_interface.py        # Chat UI logic
â”‚   â””â”€â”€ components.py            # Reusable UI components
â”‚
â”œâ”€â”€ data/
â”‚   â””â”€â”€ input_data/              # Uploaded documents
â”‚
â”œâ”€â”€ app.py                       # Streamlit entry point
â”œâ”€â”€ main.py                      # CLI entry (optional)
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ .env                         # Environment variables (ignored)
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md
```

### âš™ï¸ How It Works (High Level)
1ï¸âƒ£ Document Upload

Users upload PDF or TXT documents through the Streamlit interface.

2ï¸âƒ£ Chunking & Embedding

Uploaded documents are:

Split into meaningful chunks

Converted into vector embeddings using Sentence Transformers

3ï¸âƒ£ Vector Storage

All embeddings are stored in a FAISS vector database for efficient similarity search.

4ï¸âƒ£ Query Processing

When a user asks a question:

Relevant document chunks are retrieved

Context is injected into the LLM prompt

A grounded, document-based response is generated

5ï¸âƒ£ Response Generation

The system produces:

Accurate answers

Context-aware explanations

Source-backed responses

### ğŸš€ Ideal Use Cases

Academic research assistance

Legal document analysis

Technical documentation Q&A

Knowledge base exploration

Enterprise document intelligence

### ğŸ› ï¸ Setup Instructions
1ï¸âƒ£ Clone Repository
git clone https://github.com/rohanmangale-da-ds/GA03_Research_Intelligence_System.git
cd GA03_Research_Intelligence_System

2ï¸âƒ£ Create Virtual Environment
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

3ï¸âƒ£ Install Dependencies
pip install -r requirements.txt

4ï¸âƒ£ Configure Environment Variables

Create a .env file:

GROQ_API_KEY=your_api_key_here

5ï¸âƒ£ Run the App
streamlit run app.py

### ğŸ”’ Notes

.env is excluded from Git for security

API keys should never be committed

The app works fully offline after document ingestion
